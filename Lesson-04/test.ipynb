{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X, y = sklearn.datasets.make_moons(200, noise=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = len(X)       # size of training set\n",
    "nn_input_dim = 2\n",
    "nn_output_dim = 2\n",
    "\n",
    "lr = 0.01\n",
    "reg_lambda = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model):\n",
    "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
    "    z1 = X.dot(W1) + b1\n",
    "    a1 = np.tanh(z1)\n",
    "\n",
    "    z2 = a1.dot(W2) + b2\n",
    "\n",
    "    exp_scores = np.exp(z2)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "    print(probs)\n",
    "    log_probs = -np.log(probs[range(num_examples), y])\n",
    "    print(log_probs)\n",
    "    loss = np.sum(log_probs)\n",
    "\n",
    "    return 1./num_examples * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3552745  0.6447255 ]\n",
      " [0.05461035 0.94538965]\n",
      " [0.73602386 0.26397614]\n",
      " [0.79775572 0.20224428]\n",
      " [0.08251806 0.91748194]\n",
      " [0.09378509 0.90621491]\n",
      " [0.27673467 0.72326533]\n",
      " [0.10066617 0.89933383]\n",
      " [0.29960996 0.70039004]\n",
      " [0.06437229 0.93562771]\n",
      " [0.86600661 0.13399339]\n",
      " [0.38485434 0.61514566]\n",
      " [0.07510544 0.92489456]\n",
      " [0.10438617 0.89561383]\n",
      " [0.94786321 0.05213679]\n",
      " [0.20964247 0.79035753]\n",
      " [0.5209719  0.4790281 ]\n",
      " [0.3795646  0.6204354 ]\n",
      " [0.66358415 0.33641585]\n",
      " [0.96323413 0.03676587]\n",
      " [0.11057356 0.88942644]\n",
      " [0.10662802 0.89337198]\n",
      " [0.65036896 0.34963104]\n",
      " [0.11927758 0.88072242]\n",
      " [0.86953336 0.13046664]\n",
      " [0.5060445  0.4939555 ]\n",
      " [0.09535293 0.90464707]\n",
      " [0.11046452 0.88953548]\n",
      " [0.61469968 0.38530032]\n",
      " [0.73707972 0.26292028]\n",
      " [0.35967842 0.64032158]\n",
      " [0.85252846 0.14747154]\n",
      " [0.11528484 0.88471516]\n",
      " [0.67421996 0.32578004]\n",
      " [0.44344062 0.55655938]\n",
      " [0.17353945 0.82646055]\n",
      " [0.25025883 0.74974117]\n",
      " [0.18880479 0.81119521]\n",
      " [0.93110103 0.06889897]\n",
      " [0.8163652  0.1836348 ]\n",
      " [0.1248468  0.8751532 ]\n",
      " [0.87218167 0.12781833]\n",
      " [0.47159656 0.52840344]\n",
      " [0.44718713 0.55281287]\n",
      " [0.07700566 0.92299434]\n",
      " [0.88780446 0.11219554]\n",
      " [0.15184493 0.84815507]\n",
      " [0.92024942 0.07975058]\n",
      " [0.34238852 0.65761148]\n",
      " [0.09331377 0.90668623]\n",
      " [0.9519469  0.0480531 ]\n",
      " [0.22641883 0.77358117]\n",
      " [0.11074128 0.88925872]\n",
      " [0.83348737 0.16651263]\n",
      " [0.07506693 0.92493307]\n",
      " [0.35879756 0.64120244]\n",
      " [0.47690157 0.52309843]\n",
      " [0.08343336 0.91656664]\n",
      " [0.75329258 0.24670742]\n",
      " [0.87745899 0.12254101]\n",
      " [0.45370103 0.54629897]\n",
      " [0.92967175 0.07032825]\n",
      " [0.07404109 0.92595891]\n",
      " [0.27817036 0.72182964]\n",
      " [0.09514846 0.90485154]\n",
      " [0.9324046  0.0675954 ]\n",
      " [0.87892817 0.12107183]\n",
      " [0.08166288 0.91833712]\n",
      " [0.68201864 0.31798136]\n",
      " [0.94486434 0.05513566]\n",
      " [0.13090535 0.86909465]\n",
      " [0.95562454 0.04437546]\n",
      " [0.35020571 0.64979429]\n",
      " [0.9116299  0.0883701 ]\n",
      " [0.14452658 0.85547342]\n",
      " [0.93905318 0.06094682]\n",
      " [0.53607799 0.46392201]\n",
      " [0.26101621 0.73898379]\n",
      " [0.57917734 0.42082266]\n",
      " [0.19057412 0.80942588]\n",
      " [0.12705923 0.87294077]\n",
      " [0.91004407 0.08995593]\n",
      " [0.1123262  0.8876738 ]\n",
      " [0.26362023 0.73637977]\n",
      " [0.64028119 0.35971881]\n",
      " [0.90379232 0.09620768]\n",
      " [0.18751416 0.81248584]\n",
      " [0.92082355 0.07917645]\n",
      " [0.15162971 0.84837029]\n",
      " [0.16266115 0.83733885]\n",
      " [0.47173463 0.52826537]\n",
      " [0.27650892 0.72349108]\n",
      " [0.11541095 0.88458905]\n",
      " [0.93600456 0.06399544]\n",
      " [0.1559667  0.8440333 ]\n",
      " [0.10085973 0.89914027]\n",
      " [0.07374508 0.92625492]\n",
      " [0.15680752 0.84319248]\n",
      " [0.93622448 0.06377552]\n",
      " [0.50420779 0.49579221]\n",
      " [0.0460408  0.9539592 ]\n",
      " [0.21759213 0.78240787]\n",
      " [0.77057127 0.22942873]\n",
      " [0.13371886 0.86628114]\n",
      " [0.9285235  0.0714765 ]\n",
      " [0.65810782 0.34189218]\n",
      " [0.88055177 0.11944823]\n",
      " [0.93778431 0.06221569]\n",
      " [0.07629771 0.92370229]\n",
      " [0.70113859 0.29886141]\n",
      " [0.92532731 0.07467269]\n",
      " [0.77892556 0.22107444]\n",
      " [0.89085992 0.10914008]\n",
      " [0.89361669 0.10638331]\n",
      " [0.25418406 0.74581594]\n",
      " [0.05088373 0.94911627]\n",
      " [0.66171587 0.33828413]\n",
      " [0.15745798 0.84254202]\n",
      " [0.14282269 0.85717731]\n",
      " [0.34901481 0.65098519]\n",
      " [0.43513028 0.56486972]\n",
      " [0.87705675 0.12294325]\n",
      " [0.7217963  0.2782037 ]\n",
      " [0.76015336 0.23984664]\n",
      " [0.75867802 0.24132198]\n",
      " [0.94768376 0.05231624]\n",
      " [0.19000669 0.80999331]\n",
      " [0.40935542 0.59064458]\n",
      " [0.09520697 0.90479303]\n",
      " [0.25961299 0.74038701]\n",
      " [0.30304046 0.69695954]\n",
      " [0.89557032 0.10442968]\n",
      " [0.94879359 0.05120641]\n",
      " [0.29124711 0.70875289]\n",
      " [0.1059045  0.8940955 ]\n",
      " [0.14814    0.85186   ]\n",
      " [0.12842665 0.87157335]\n",
      " [0.90329694 0.09670306]\n",
      " [0.220591   0.779409  ]\n",
      " [0.3810973  0.6189027 ]\n",
      " [0.68625774 0.31374226]\n",
      " [0.76625439 0.23374561]\n",
      " [0.63052729 0.36947271]\n",
      " [0.94659642 0.05340358]\n",
      " [0.89429938 0.10570062]\n",
      " [0.20022445 0.79977555]\n",
      " [0.47502754 0.52497246]\n",
      " [0.07332265 0.92667735]\n",
      " [0.70033298 0.29966702]\n",
      " [0.5865092  0.4134908 ]\n",
      " [0.17869648 0.82130352]\n",
      " [0.05128209 0.94871791]\n",
      " [0.27838656 0.72161344]\n",
      " [0.646781   0.353219  ]\n",
      " [0.12724397 0.87275603]\n",
      " [0.90193779 0.09806221]\n",
      " [0.07288067 0.92711933]\n",
      " [0.45413554 0.54586446]\n",
      " [0.55429581 0.44570419]\n",
      " [0.47424064 0.52575936]\n",
      " [0.34644501 0.65355499]\n",
      " [0.06979475 0.93020525]\n",
      " [0.47016623 0.52983377]\n",
      " [0.097509   0.902491  ]\n",
      " [0.12309064 0.87690936]\n",
      " [0.15488339 0.84511661]\n",
      " [0.64679169 0.35320831]\n",
      " [0.19669206 0.80330794]\n",
      " [0.06965841 0.93034159]\n",
      " [0.06590942 0.93409058]\n",
      " [0.53368291 0.46631709]\n",
      " [0.91016362 0.08983638]\n",
      " [0.94455182 0.05544818]\n",
      " [0.87305913 0.12694087]\n",
      " [0.39863395 0.60136605]\n",
      " [0.12045568 0.87954432]\n",
      " [0.30976682 0.69023318]\n",
      " [0.91579214 0.08420786]\n",
      " [0.90628637 0.09371363]\n",
      " [0.63183107 0.36816893]\n",
      " [0.07902977 0.92097023]\n",
      " [0.93123543 0.06876457]\n",
      " [0.16275181 0.83724819]\n",
      " [0.06060827 0.93939173]\n",
      " [0.19901413 0.80098587]\n",
      " [0.6684416  0.3315584 ]\n",
      " [0.70217743 0.29782257]\n",
      " [0.07358571 0.92641429]\n",
      " [0.91248651 0.08751349]\n",
      " [0.93512917 0.06487083]\n",
      " [0.92814438 0.07185562]\n",
      " [0.61328115 0.38671885]\n",
      " [0.26496766 0.73503234]\n",
      " [0.24847775 0.75152225]\n",
      " [0.70278676 0.29721324]\n",
      " [0.92816435 0.07183565]\n",
      " [0.14936897 0.85063103]\n",
      " [0.39250667 0.60749333]\n",
      " [0.70499382 0.29500618]\n",
      " [0.10572217 0.89427783]]\n",
      "[1.03486455 0.0561581  1.33189657 0.22595285 0.08612238 0.09847879\n",
      " 1.28469611 0.10610098 1.20527377 0.06653763 0.14386273 0.4858962\n",
      " 0.07807554 0.11024595 0.05354508 1.5623517  0.65205918 0.47733379\n",
      " 0.41009961 0.03745877 0.11717847 0.11275223 0.43021545 0.12701277\n",
      " 0.13979858 0.70530984 0.10021039 0.11705589 0.95373219 0.30505923\n",
      " 1.02254491 0.15954869 0.12248954 1.12153284 0.81319137 0.1906031\n",
      " 0.28802725 1.66704168 0.07138748 1.69480625 0.13335632 0.13675754\n",
      " 0.7516314  0.59273573 0.08013218 0.11900377 1.8848955  0.08311054\n",
      " 0.41914098 0.09795884 0.04924603 0.25672468 0.11736706 0.18213673\n",
      " 0.0780339  1.02499694 0.74044516 0.0871205  0.28330157 0.13072506\n",
      " 0.60458889 0.07292372 0.07692542 1.27952153 0.0999844  0.06998844\n",
      " 0.1290521  0.08519072 0.38269828 0.05671392 0.14030324 0.04539018\n",
      " 0.43109944 2.42622156 0.15610025 0.06288317 0.76803883 1.34317277\n",
      " 0.54614656 0.21143007 0.13588757 0.09426225 0.11915095 0.3060093\n",
      " 1.02243263 0.10115568 1.67390091 0.08248685 0.16443808 0.17752645\n",
      " 0.75133868 1.28551218 0.12263209 0.06613493 0.16956333 0.10631623\n",
      " 0.07660579 0.17056002 0.0659     0.70159838 0.04713438 0.2453791\n",
      " 0.26062313 2.01201577 0.07415959 1.07325985 0.12720656 0.0642353\n",
      " 0.07936546 0.3550497  0.07760776 0.24983979 0.11556808 0.11247835\n",
      " 1.36969663 0.05222397 0.41291901 0.17133175 0.15411048 1.05264091\n",
      " 0.83210979 0.13118358 1.2794017  0.27423508 1.42162322 0.05373442\n",
      " 1.66069598 0.52654082 0.10004906 0.30058224 1.19388896 0.11029454\n",
      " 0.05256401 0.34424834 0.11194269 0.16033309 0.13745525 0.10170394\n",
      " 0.24921933 0.96470057 1.15918346 1.45352188 0.46119884 0.05488244\n",
      " 0.11171468 1.60831629 0.64440947 0.07614983 0.35619937 0.88312001\n",
      " 0.19686254 0.05264377 1.27874463 0.43574753 0.13609923 0.10320972\n",
      " 0.07567299 0.60538458 0.59005678 0.7460404  0.4253286  0.07235002\n",
      " 0.75466896 0.10259656 0.13135165 0.16828067 0.435731   0.21901715\n",
      " 0.07220346 0.06818186 0.62795342 0.09413089 0.05704473 0.135752\n",
      " 0.50855146 0.12835133 0.3707258  0.08796586 0.09839994 0.45913322\n",
      " 0.08232757 0.07124316 0.17763473 0.0625227  0.22191197 0.40280624\n",
      " 0.35356916 0.07643374 0.09158198 0.06707061 0.07456798 0.4889318\n",
      " 1.32814749 1.39240197 1.21330543 0.07454647 0.16177681 0.49841409\n",
      " 0.34956624 0.11173878]\n",
      "Loss after iteration 0: 0.424289\n"
     ]
    }
   ],
   "source": [
    "def build_model(nn_hdim, num_passes=30000, print_loss=False):\n",
    "    W1 = np.random.randn(nn_input_dim, nn_hdim) / np.sqrt(nn_input_dim)\n",
    "    b1 = np.zeros((1, nn_hdim))\n",
    "    W2 = np.random.randn(nn_hdim, nn_output_dim) / np.sqrt(nn_hdim)\n",
    "    b2 = np.zeros((1, nn_output_dim))\n",
    "\n",
    "    model = {}\n",
    "\n",
    "    # Gradient descent.\n",
    "    for i in range(0, num_passes):\n",
    "        # forward\n",
    "        z1 = X.dot(W1) + b1\n",
    "        a1 = np.tanh(z1)\n",
    "        z2 = a1.dot(W2) + b2\n",
    "        exp_scores = np.exp(z2)\n",
    "\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)   # this is softmax\n",
    "\n",
    "        # bp\n",
    "        delta3 = probs\n",
    "        delta3[range(num_examples), y] -= 1    # this is the derivative of softmax [no need to thoroughly understand yet]\n",
    "                                      #                                   [we'll revisit in weeks later]\n",
    "        dW2 = (a1.T).dot(delta3)\n",
    "        db2 = np.sum(delta3, axis=0, keepdims=True)\n",
    "        delta2 = delta3.dot(W2.T) * (1 - np.power(a1, 2)) # tanh derivative\n",
    "        dW1 = np.dot(X.T, delta2)\n",
    "        db1 = np.sum(delta2, axis=0)\n",
    "\n",
    "        # optional\n",
    "        W1 += -lr * dW1\n",
    "        b1 += -lr * db1\n",
    "        W2 += -lr * dW2\n",
    "        b2 += -lr * db2\n",
    "\n",
    "        model = {'W1': W1, 'b1':b1, 'W2':W2, 'b2': b2}\n",
    "\n",
    "        if print_loss and i % 1000 == 0:\n",
    "            print(\"Loss after iteration %i: %f\" % (i, calculate_loss(model)))\n",
    "        break\n",
    "    return model\n",
    "\n",
    "\n",
    "# n-dimesional hidden layer\n",
    "model = build_model(10, print_loss = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
